{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "import os # read dotenv values\n",
    "BUCKET_NAME = os.environ.get(\"BUCKET_NAME\")\n",
    "FILE_NAME = os.environ.get(\"CSV_NAME\")\n",
    "print(BUCKET_NAME)\n",
    "print(FILE_NAME)\n",
    "# read the content of data bucket\n",
    "bucket = s3.Bucket(BUCKET_NAME)\n",
    "\n",
    "\n",
    "# list all files in this bucket\n",
    "for obj in bucket.objects.all():\n",
    "    print(obj.key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv from s3\n",
    "import csv\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "def from_s3(s3_uri:str) -> pd.DataFrame:\n",
    "    client = boto3.client(\"s3\")\n",
    "    parsed_s3 = urlparse(s3_uri)\n",
    "    path= parsed_s3.path[1:]\n",
    "    obj = client.get_object(Bucket=parsed_s3.netloc, Key=path)\n",
    "    csv_in_bytes = BytesIO(obj[\"Body\"].read())\n",
    "    print(obj[\"Body\"])\n",
    "    return pd.read_csv(csv_in_bytes)\n",
    "\n",
    "\n",
    "# read data from s3 bucket\n",
    "data_location = f\"s3://{BUCKET_NAME}/{FILE_NAME}\"\n",
    "df = from_s3 (data_location)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial data exploration to test if s3 is working\n",
    "df.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = df.shape[1]\n",
    "print(df.shape)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop= [\"City or Regency\", \"Time Zone\", \"Country\", \"Continent\", \"Province\", \"Location ISO Code\", \"Total Regencies\", \"Total Regencies\", \"Island\", \"Special Status\", \"Longitude\", \"Latitude\", \"Location Level\", \"Area (km2)\"]\n",
    "df = df.drop(cols_to_drop, axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop indonisa columns, \n",
    "indo_rows_to_drop = df.loc[df[\"Location\"] == \"Indonesia\"]\n",
    "indo_rows_to_drop.head() \n",
    "index_to_delete = indo_rows_to_drop.index\n",
    "df.drop(index_to_delete, inplace=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean total rural village for jakarta\n",
    "# jakarta = df.loc[df[\"Location\"] == \"DKI Jakarta\"]\n",
    "# jakarta[\"Total Rural Villages\"] = 0\n",
    "# df.loc[\"Location\",\"DKI Jakarta\"] = jakarta\n",
    "\n",
    "df.loc[df[\"Location\"] == \"DKI Jakarta\", \"Total Rural Villages\"] = 0\n",
    "\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean percentage sign\n",
    "col_with_percent = [\"Case Fatality Rate\", \"Case Recovered Rate\"]\n",
    "print(df[col_with_percent].head())\n",
    "df[col_with_percent] = df[col_with_percent].apply( lambda s: s.str.rstrip('%').astype(float) / 100.0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean na data\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill total city and total urban villages to 0 if there is nan\n",
    "df [\"Total Urban Villages\"] = df[\"Total Urban Villages\"].fillna(0)\n",
    "df [\"Total Cities\"] = df [\"Total Cities\"].fillna(0)\n",
    "\n",
    "# compare result\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interporate missing growth factor data\n",
    "df = df.interpolate(method ='linear', limit_direction ='forward')\n",
    "df.loc[0, \"Growth Factor of New Cases\"]= 0\n",
    "df.loc[0, \"Growth Factor of New Deaths\"]= 0\n",
    "# round off 2 decimals\n",
    "df[\"Growth Factor of New Cases\"] = df[\"Growth Factor of New Cases\"].apply(lambda x: round (x,3))\n",
    "df[\"Growth Factor of New Deaths\"] = df[\"Growth Factor of New Deaths\"].apply(lambda x: round (x,3))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the date\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to bucket\n",
    "# save the cleaned csv locally\n",
    "result_file_name: str = os.environ.get(\"CSV_CLEANED_NAME\", \"result\")\n",
    "path=f\"{os.getcwd()}/{result_file_name}.csv\"\n",
    "print(path)\n",
    "df.to_csv(path)\n",
    "\n",
    "# upload csv to s3 bucket \n",
    "def to_s3(s3_uri:str, object_name:str = None) -> pd.DataFrame:\n",
    "    client = boto3.client(\"s3\")\n",
    "    parsed_s3 = urlparse(s3_uri)\n",
    "    file_name= parsed_s3.path[1:]\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "    obj = client.upload_file(file_name, Bucket=parsed_s3.netloc,Key=object_name)\n",
    "    print(obj)\n",
    "\n",
    "\n",
    "# read data from s3 bucket\n",
    "upload_location = f\"s3://{BUCKET_NAME}/{result_file_name}.csv\"\n",
    "to_s3 (upload_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial graphing of data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "n_by_date = df.groupby('Date')[[\"Total Cases\", \"Total Deaths\"]].sum()\n",
    "n_by_date.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('tensorflow-starter-ktE5xTfk')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6e08394f27a7bfa2bb4e7efe66eae91ceaa77b3457ffe42cf775fad798ee67d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
