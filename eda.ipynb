{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "import os # read dotenv values\n",
    "BUCKET_NAME = os.environ.get(\"BUCKET_NAME\")\n",
    "FILE_NAME = os.environ.get(\"CSV_NAME\")\n",
    "print(BUCKET_NAME)\n",
    "print(FILE_NAME)\n",
    "# read the content of data bucket\n",
    "bucket = s3.Bucket(BUCKET_NAME)\n",
    "\n",
    "\n",
    "# list all files in this bucket\n",
    "for obj in bucket.objects.all():\n",
    "    print(obj.key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv from s3\n",
    "import csv\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "def from_s3(s3_uri:str) -> pd.DataFrame:\n",
    "    client = boto3.client(\"s3\")\n",
    "    parsed_s3 = urlparse(s3_uri)\n",
    "    path= parsed_s3.path[1:]\n",
    "    obj = client.get_object(Bucket=parsed_s3.netloc, Key=path)\n",
    "    csv_in_bytes = BytesIO(obj[\"Body\"].read())\n",
    "    print(obj[\"Body\"])\n",
    "    return pd.read_csv(csv_in_bytes)\n",
    "\n",
    "\n",
    "# read data from s3 bucket\n",
    "data_location = f\"s3://{BUCKET_NAME}/{FILE_NAME}\"\n",
    "df = from_s3 (data_location)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial data exploration to test if s3 is working\n",
    "df.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = df.shape[1]\n",
    "print(df.shape)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop= [\"City or Regency\", \"Time Zone\", \"Country\", \"Continent\", \"Province\", \"Location ISO Code\", \"Total Regencies\", \"Island\", \"Special Status\", \"Longitude\", \"Latitude\", \"Location Level\", \"Area (km2)\"]\n",
    "df = df.drop(cols_to_drop, axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop indonisa columns, \n",
    "indo_rows_to_drop = df.loc[df[\"Location\"] == \"Indonesia\"]\n",
    "indo_rows_to_drop.head() \n",
    "index_to_delete = indo_rows_to_drop.index\n",
    "df.drop(index_to_delete, inplace=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean total rural village for jakarta\n",
    "# jakarta = df.loc[df[\"Location\"] == \"DKI Jakarta\"]\n",
    "# jakarta[\"Total Rural Villages\"] = 0\n",
    "# df.loc[\"Location\",\"DKI Jakarta\"] = jakarta\n",
    "\n",
    "df.loc[df[\"Location\"] == \"DKI Jakarta\", \"Total Rural Villages\"] = 0\n",
    "\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean percentage sign\n",
    "col_with_percent = [\"Case Fatality Rate\", \"Case Recovered Rate\"]\n",
    "print(df[col_with_percent].head())\n",
    "df[col_with_percent] = df[col_with_percent].apply( lambda s: s.str.rstrip('%').astype(float) / 100.0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean na data\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill total city and total urban villages to 0 if there is nan\n",
    "df [\"Total Urban Villages\"] = df[\"Total Urban Villages\"].fillna(0)\n",
    "df [\"Total Cities\"] = df [\"Total Cities\"].fillna(0)\n",
    "\n",
    "# compare result\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interporate missing growth factor data\n",
    "df = df.interpolate(method ='linear', limit_direction ='forward')\n",
    "df.loc[0, \"Growth Factor of New Cases\"]= 0\n",
    "df.loc[0, \"Growth Factor of New Deaths\"]= 0\n",
    "# round off 2 decimals\n",
    "df[\"Growth Factor of New Cases\"] = df[\"Growth Factor of New Cases\"].apply(lambda x: round (x,3))\n",
    "df[\"Growth Factor of New Deaths\"] = df[\"Growth Factor of New Deaths\"].apply(lambda x: round (x,3))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the date\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to bucket\n",
    "# save the cleaned csv locally\n",
    "result_file_name: str = os.environ.get(\"CSV_CLEANED_NAME\", \"result\")\n",
    "path=f\"{os.getcwd()}/{result_file_name}.csv\"\n",
    "print(path)\n",
    "df.to_csv(path)\n",
    "\n",
    "# upload csv to s3 bucket \n",
    "def to_s3(s3_uri:str, object_name:str = None) -> pd.DataFrame:\n",
    "    client = boto3.client(\"s3\")\n",
    "    parsed_s3 = urlparse(s3_uri)\n",
    "    file_name= parsed_s3.path[1:]\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "    obj = client.upload_file(file_name, Bucket=parsed_s3.netloc,Key=object_name)\n",
    "    print(obj)\n",
    "\n",
    "\n",
    "# read data from s3 bucket\n",
    "upload_location = f\"s3://{BUCKET_NAME}/{result_file_name}.csv\"\n",
    "to_s3 (upload_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial graphing of data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "n_by_date = df.groupby('Date')[[\"Total Cases\", \"Total Deaths\"]].sum()\n",
    "n_by_date.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = n_by_date[\"Total Cases\"]\n",
    "y = n_by_date[\"Total Deaths\"]\n",
    "\n",
    "x_scaler=10\n",
    "x_max_scaled = x.max() /x_scaler\n",
    "\n",
    "# Plot linear sequence, and set tick labels to the same color\n",
    "ax.set_ylim(0,x_max_scaled)\n",
    "ax.plot(y, color='red', label = \"Total Death\")\n",
    "ax.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Generate a new Axes instance, on the twin-X axes (same position)\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# Plot exponential sequence, set scale to logarithmic and change tick color\n",
    "ax2.plot(x, color='blue', label= \"Total Cases\")\n",
    "ax2.tick_params(axis='y', labelcolor='blue')\n",
    "ax2.ticklabel_format(useOffset=False, axis=\"y\", style=\"plain\")\n",
    "\n",
    "ax2.set_ylabel('Total Cases')\n",
    "ax2.set_xlabel(\"Total Death\")\n",
    "ax.set_xlabel('Date (by month)')\n",
    "\n",
    "fig.legend(loc = 'upper left')\n",
    "plt.title(\"Total Death and Total Cases by month\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new death and cases\n",
    "n_by_date = df.groupby('Date')[[\"New Cases\", \"New Deaths\"]].sum()\n",
    "n_by_date.head(50)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x_label, y_label = [\"New Cases\", \"New Deaths\"]\n",
    "\n",
    "x = n_by_date[x_label]\n",
    "y = n_by_date[y_label]\n",
    "\n",
    "x_scaler=10\n",
    "x_max_scaled = x.max() /x_scaler\n",
    "\n",
    "# Plot linear sequence, and set tick labels to the same color\n",
    "ax.set_ylim(0,x_max_scaled)\n",
    "ax.plot(y, color='red', label = y_label)\n",
    "ax.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Generate a new Axes instance, on the twin-X axes (same position)\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# Plot exponential sequence, set scale to logarithmic and change tick color\n",
    "ax2.plot(x, color='blue', label= x_label)\n",
    "ax2.tick_params(axis='y', labelcolor='blue')\n",
    "ax2.ticklabel_format(useOffset=False, axis=\"y\", style=\"plain\")\n",
    "\n",
    "ax2.set_ylabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.set_xlabel('Date (by month)')\n",
    "\n",
    "fig.legend(loc = 'upper left')\n",
    "plt.title(f\"{x_label} and {y_label} by month\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by region \n",
    "\n",
    "n_by_date = df.groupby(['Date', 'Location'])[[\"New Cases\", \"New Deaths\"]].sum()\n",
    "print(type(n_by_date))\n",
    "print(n_by_date.columns)\n",
    "\n",
    "# all unique locations\n",
    "# all_locations = df[\"Location\"].unique()\n",
    "# print(all_locations)\n",
    "print(n_by_date.loc[n_by_date['New Cases']==n_by_date['New Cases'].max()])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "n_by_date[\"New Cases\"].unstack().plot(ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new death by locations\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "n_by_date[\"New Deaths\"].unstack().plot(ax=ax)\n",
    "print(n_by_date.loc[n_by_date['New Deaths']==n_by_date['New Deaths'].max()])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by region \n",
    "\n",
    "n_by_loc = df.groupby(['Location'])[[\"New Cases\", \"New Deaths\"]].sum()\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25, 20))\n",
    "\n",
    "x_label, y_label = [\"New Cases\", \"New Deaths\"]\n",
    "\n",
    "x = n_by_loc[x_label]\n",
    "y = n_by_loc[y_label]\n",
    "\n",
    "x_scaler=10\n",
    "x_max_scaled = x.max() / x_scaler\n",
    "\n",
    "\n",
    "# plot second bar chart on same graph\n",
    "ind = np.arange(len(n_by_loc))\n",
    "width = 0.4\n",
    "\n",
    "# Plot linear sequence, and set tick labels to the same color\n",
    "# ax.set_ylim(0,x_max_scaled)\n",
    "ax.barh(ind, y*x_scaler, width, color='red', label = y_label)\n",
    "ax.barh(ind+width, x, width, color='blue', label = x_label)\n",
    "ax.tick_params(axis='x', labelcolor='blue')\n",
    "ax.set(yticks=ind + width, yticklabels=n_by_loc.index, ylim=[2*width - 1, len(n_by_loc)])\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "ax.set_xlabel(f\"{x_label} by Location\")\n",
    "\n",
    "\n",
    "ax2 = ax.twiny()\n",
    "ax2.set_xlim(0,y.max() * 1.2)\n",
    "x_death_range = np.arange(0, x_max_scaled, 10000)\n",
    "ax2.set_xticks(x_death_range)\n",
    "ax2.tick_params(axis='x', labelcolor='red')\n",
    "ax2.set_xlabel(f\"{y_label} by Location\")\n",
    "              \n",
    "\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy() \n",
    "    ax.text(x+width, \n",
    "            y+height/2, \n",
    "            str(round(width/x_scaler)), \n",
    "            fontsize=8,\n",
    "           color='grey')\n",
    "\n",
    "plt.title(f\"{x_label} and {y_label} by Location\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_by_loc = df.groupby(['Location'])[[\"New Cases\", \"New Deaths\"]].sum()\n",
    "location_pop = df[['Location', 'Population Density']]\n",
    "# get unique location's population density\n",
    "location_pop=location_pop.drop_duplicates(subset=['Location'])\n",
    "\n",
    "# combine dataframes\n",
    "result_df = n_by_loc.merge(location_pop, how = 'inner', on = ['Location'])\n",
    "result_df.head(40)\n",
    "\n",
    "# bco efficients between data\n",
    "import numpy as np\n",
    "death = result_df['New Deaths']\n",
    "case = result_df['New Cases']\n",
    "density = result_df['Population Density']\n",
    "r_death_loc = np.corrcoef(density, death)\n",
    "print(f'the coefficient between density and death is {r_death_loc}')\n",
    "r_death_case = np.corrcoef(case, death)\n",
    "print(f'the coefficient between case and death is {r_death_case}')\n",
    "r_case_loc = np.corrcoef(density, case)\n",
    "print(f'the coefficient between density and case is {r_case_loc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_by_loc = df.groupby(['Location'])[[\"New Cases\", \"New Deaths\"]].sum()\n",
    "urban_df = df[['Location', 'Total Cities', 'Total Districts', 'Total Urban Villages', 'Total Rural Villages']]\n",
    "# get unique location's population density\n",
    "urban_df = urban_df.drop_duplicates(subset=['Location'])\n",
    "\n",
    "urban_df['rural_ratio'] = urban_df['Total Rural Villages'] / (urban_df['Total Rural Villages'] + urban_df['Total Districts'] + urban_df['Total Urban Villages'] + urban_df['Total Cities'])\n",
    "\n",
    "\n",
    "urban_df['urban_ratio'] = 1- urban_df['rural_ratio']\n",
    "\n",
    "urban_df.head()\n",
    "\n",
    "# combine dataframes\n",
    "result_df = n_by_loc.merge(urban_df, how = 'inner', on = ['Location'])\n",
    "result_df.head(40)\n",
    "\n",
    "# bco efficients between data\n",
    "import numpy as np\n",
    "death = result_df['New Deaths']\n",
    "case = result_df['New Cases']\n",
    "urban_rate = result_df['urban_ratio']\n",
    "rural_rate = result_df['rural_ratio'] \n",
    "\n",
    "r_death_urban = np.corrcoef(urban_rate, death)\n",
    "print(f'the coefficient between urban_rate and death is {r_death_urban}')\n",
    "\n",
    "r_death_rural = np.corrcoef(rural_rate, death)\n",
    "print(f'the coefficient between rural_rate and death is {r_death_rural}')\n",
    "\n",
    "r_death_case = np.corrcoef(urban_rate, case)\n",
    "print(f'the coefficient between urban_rate and case is {r_death_case}')\n",
    "r_case_loc = np.corrcoef(rural_rate, case)\n",
    "print(f'the coefficient between rural and case is {r_case_loc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_by_loc = df.groupby(['Location'])[[\"New Cases\", \"New Deaths\"]].sum()\n",
    "location_pop = df[['Location', 'Population Density']]\n",
    "# get unique location's population density\n",
    "location_pop=location_pop.drop_duplicates(subset=['Location'])\n",
    "result_df = result_df.merge(location_pop, how = 'inner', on = ['Location'])\n",
    "result_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats.kde import gaussian_kde\n",
    "from numpy import linspace\n",
    "death = result_df['New Deaths']\n",
    "median_death = death.median()\n",
    "print(median_death)\n",
    "# estimate the probability density function (PDF)\n",
    "kde = gaussian_kde(death)\n",
    "# return evenly spaced numbers over a specified interval\n",
    "dist_space = linspace(min(death), max(death), int(median_death))\n",
    "# plot the results\n",
    "plt.plot(dist_space, kde(dist_space))\n",
    "plt.ticklabel_format(useOffset=False, axis=\"y\", style=\"plain\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for data and location \n",
    "one_hot_location = pd.get_dummies(df['Location'])\n",
    "# Drop column B as it is now encoded\n",
    "df = df.drop('Location',axis = 1)\n",
    "# Join the encoded df\n",
    "col_to_drop =['Total Deaths per 100rb','Growth Factor of New Cases', 'Growth Factor of New Deaths', 'Total Deaths per Million',\n",
    "              'Total Active Cases', 'Population', 'New Cases per Million', 'Total Cases per Million','New Deaths per Million']\n",
    "df.head()\n",
    "df = df.join(one_hot_location)\n",
    "df = df.drop(col_to_drop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 20))\n",
    "\n",
    "x_label, y_label = [\"rural_ratio\", \"New Deaths\"]\n",
    "\n",
    "x = result_df[x_label]\n",
    "y = result_df[y_label]\n",
    "\n",
    "for i, txt in enumerate(result_df['Location']):\n",
    "    ax.annotate(txt, (x[i], y[i]))\n",
    "\n",
    "plt.scatter (x, y, s=80)\n",
    "plt.title(\"rural area and total death\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 20))\n",
    "\n",
    "x_label, y_label = [\"urban_ratio\", \"New Deaths\"]\n",
    "\n",
    "x = result_df[x_label]\n",
    "y = result_df[y_label]\n",
    "\n",
    "plt.scatter (x, y)\n",
    "plt.title (\"urban area and total covid death\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rural_percentage = result_df.loc[result_df[\"rural_ratio\"] > 0.7]\n",
    "total_rural_locations = len(rural_percentage)\n",
    "\n",
    "print(f\"in indonisa {total_rural_locations / len(result_df) :.2%} percent are in rural area, as the city to village ratio is > 0.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_new = result_df[result_df.Location != 'DKI Jakarta'] # drop capital data\n",
    "result_df_new = result_df_new.reset_index()\n",
    "result_df_new.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 20))\n",
    "\n",
    "x_label, y_label = [\"urban_ratio\", \"Population Density\"]\n",
    "\n",
    "x = result_df_new[x_label]\n",
    "y = result_df_new[y_label]\n",
    "\n",
    "plt.scatter (x, y)\n",
    "for i, txt in enumerate(result_df_new['Location']):\n",
    "    ax.annotate(txt, (x[i], y[i]))\n",
    "    \n",
    "#add horizontal line at a medain value of y\n",
    "median_pop_density = result_df_new[\"Population Density\"].median()\n",
    "median_urban_rate = result_df_new[\"urban_ratio\"].median()\n",
    "plt.axhline(y=median_pop_density)\n",
    "plt.axvline(x=median_urban_rate)\n",
    "\n",
    "plt.title (\"urban area and population density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 20))\n",
    "\n",
    "x_label, y_label = [\"urban_ratio\", \"Population Density\"]\n",
    "\n",
    "x = result_df_new[x_label]\n",
    "y = result_df_new[y_label]\n",
    "\n",
    "plt.scatter (x, y)\n",
    "for i, txt in enumerate(result_df_new['Location']):\n",
    "    ax.annotate(txt, (x[i], y[i]))\n",
    "    \n",
    "#add horizontal line at a medain value of y\n",
    "median_pop_density = result_df_new[\"Population Density\"].mean()\n",
    "median_urban_rate = result_df_new[\"urban_ratio\"].mean()\n",
    "plt.axhline(y=median_pop_density)\n",
    "plt.axvline(x=median_urban_rate)\n",
    "\n",
    "plt.title (\"urban area and population density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = result_df[result_df.Location != 'DKI Jakarta'] # drop capital data\n",
    "mean_pop_density = result_df_new[\"Population Density\"].mean()\n",
    "mean_urban_rate = result_df_new[\"urban_ratio\"].mean()\n",
    "\n",
    "print(f\"median pop density: {median_pop_density} and median urban rate is : {median_urban_rate}\")\n",
    "\n",
    "# select 50% data from data that have pop density < median\n",
    "mask_urban = result_df_new['urban_ratio'] < mean_urban_rate\n",
    "left_percentile_urban =result_df_new[mask_urban]\n",
    "right_percentile_urban = result_df_new[~mask_urban]\n",
    "\n",
    "# further divide left data by median of pop density\n",
    "mask_pop_left = left_percentile_urban['Population Density'] < mean_pop_density\n",
    "mask_pop_right = right_percentile_urban['Population Density'] < mean_pop_density\n",
    "left_percentile_urban_pop_top = left_percentile_urban[mask_pop_left]\n",
    "left_percentile_urban_pop_down = left_percentile_urban[~mask_pop_left]\n",
    "\n",
    "# spilt the value into 2 groups\n",
    "left_case_down_train, left_case_down_test = np.array_split(left_percentile_urban_pop_down.sample(frac=1, random_state=42), 2)\n",
    "left_case_top_train, left_case_top_test = np.array_split(left_percentile_urban_pop_top.sample(frac=1, random_state=42), 2)\n",
    "\n",
    "# same with value on right hand side\n",
    "right_percentile_urban_pop_top = right_percentile_urban[mask_pop_right]\n",
    "right_percentile_urban_pop_down = right_percentile_urban[~mask_pop_right]\n",
    "right_case_down_train, right_case_down_test = np.array_split(right_percentile_urban_pop_down.sample(frac=1, random_state=42), 2)\n",
    "right_case_top_train, right_case_top_test = np.array_split(right_percentile_urban_pop_top.sample(frac=1, random_state=42), 2)\n",
    "\n",
    "\n",
    "# train data left side\n",
    "train_left = pd.concat([left_case_down_train,left_case_top_train])\n",
    "print(len(train_left))\n",
    "\n",
    "# train data right side\n",
    "train_right = pd.concat([right_case_down_train,right_case_top_train])\n",
    "print(len(train_right))\n",
    "\n",
    "# train data left side\n",
    "test_left = pd.concat([left_case_down_test,left_case_top_test])\n",
    "print(len(test_left))\n",
    "\n",
    "# train data right side\n",
    "test_right = pd.concat([right_case_down_test,right_case_top_test])\n",
    "print(len(test_right))\n",
    "\n",
    "# only select certain data\n",
    "test_case_x, test_case_y = test_left[[\"Population Density\", \"urban_ratio\"]], test_left[[\"New Cases\"]]\n",
    "train_case_x, train_case_y = train_left[[\"Population Density\", \"urban_ratio\"]], train_left[[\"New Cases\"]]\n",
    "\n",
    "# train a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(test_case_x, test_case_y)\n",
    "\n",
    "r_sq = model.score(test_case_x, test_case_y)\n",
    "print(f\"coefficient of determination: {r_sq}\")\n",
    "print(f\"intercept: {model.intercept_}\") # if we feed into the data of aceh this is the total infection 114734\n",
    "print(f\"slope: {model.coef_}\") # when population increase, result increase by 2.47e+02 for pop density\n",
    "\n",
    "y_pred = model.predict(train_case_x)\n",
    "print(f\"predicted response:\\n{y_pred}\")\n",
    "print(train_case_y)\n",
    "# accuracy of model\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "r2_score = r2_score(train_case_y, y_pred)\n",
    "mse = mean_squared_error(train_case_y, y_pred)\n",
    "print (f\"our accuracy score is {r2_score}\")\n",
    "print (f\"our MSE is {mse}\")\n",
    "print(f\"rmse is {np.sqrt(mse)}\")\n",
    "\n",
    "mae = mean_absolute_error(train_case_y, y_pred)\n",
    "print(f\"mae is {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = result_df[result_df.Location != 'DKI Jakarta'] # drop capital data\n",
    "mean_pop_density = result_df_new[\"Population Density\"].mean()\n",
    "mean_urban_rate = result_df_new[\"urban_ratio\"].mean()\n",
    "\n",
    "print(f\"median pop density: {median_pop_density} and median urban rate is : {median_urban_rate}\")\n",
    "\n",
    "# select 50% data from data that have pop density < median\n",
    "mask_urban = result_df_new['urban_ratio'] < mean_urban_rate\n",
    "left_percentile_urban =result_df_new[mask_urban]\n",
    "right_percentile_urban = result_df_new[~mask_urban]\n",
    "\n",
    "# further divide left data by median of pop density\n",
    "mask_pop_left = left_percentile_urban['Population Density'] < mean_pop_density\n",
    "mask_pop_right = right_percentile_urban['Population Density'] < mean_pop_density\n",
    "left_percentile_urban_pop_top = left_percentile_urban[mask_pop_left]\n",
    "left_percentile_urban_pop_down = left_percentile_urban[~mask_pop_left]\n",
    "\n",
    "# spilt the value into 2 groups\n",
    "left_case_down_train, left_case_down_test = np.array_split(left_percentile_urban_pop_down.sample(frac=1, random_state=42), 2)\n",
    "left_case_top_train, left_case_top_test = np.array_split(left_percentile_urban_pop_top.sample(frac=1, random_state=42), 2)\n",
    "\n",
    "# same with value on right hand side\n",
    "right_percentile_urban_pop_top = right_percentile_urban[mask_pop_right]\n",
    "right_percentile_urban_pop_down = right_percentile_urban[~mask_pop_right]\n",
    "right_case_down_train, right_case_down_test = np.array_split(right_percentile_urban_pop_down.sample(frac=1, random_state=42), 2)\n",
    "right_case_top_train, right_case_top_test = np.array_split(right_percentile_urban_pop_top.sample(frac=1, random_state=42), 2)\n",
    "\n",
    "\n",
    "# train data left side\n",
    "train_left = pd.concat([left_case_down_train,left_case_top_train])\n",
    "print(len(train_left))\n",
    "\n",
    "# train data right side\n",
    "train_right = pd.concat([right_case_down_train,right_case_top_train])\n",
    "print(len(train_right))\n",
    "\n",
    "# train data left side\n",
    "test_left = pd.concat([left_case_down_test,left_case_top_test])\n",
    "print(len(test_left))\n",
    "\n",
    "# train data right side\n",
    "test_right = pd.concat([right_case_down_test,right_case_top_test])\n",
    "print(len(test_right))\n",
    "\n",
    "# only select certain data\n",
    "test_case_x, test_case_y = test_left[[\"Population Density\", \"urban_ratio\"]], test_left[[\"New Deaths\"]]\n",
    "train_case_x, train_case_y = train_left[[\"Population Density\", \"urban_ratio\"]], train_left[[\"New Deaths\"]]\n",
    "\n",
    "# train a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(test_case_x, test_case_y)\n",
    "\n",
    "r_sq = model.score(test_case_x, test_case_y)\n",
    "print(f\"coefficient of determination: {r_sq}\")\n",
    "print(f\"intercept: {model.intercept_}\") # if we feed into the data of aceh this is the total infection 114734\n",
    "print(f\"slope: {model.coef_}\") # when population increase, result increase by 2.47e+02 for pop density\n",
    "\n",
    "y_pred = model.predict(train_case_x)\n",
    "print(f\"predicted response:\\n{y_pred}\")\n",
    "print(train_case_y)\n",
    "# accuracy of model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "r2_score = r2_score(train_case_y, y_pred)\n",
    "mse = mean_squared_error(train_case_y, y_pred, multioutput='uniform_average')\n",
    "\n",
    "print (f\"our accuracy score is {r2_score}\")\n",
    "print (f\"our MSE is {mse}\")\n",
    "print(f\"rmse is {np.sqrt(mse)}\")\n",
    "\n",
    "mae = mean_absolute_error(train_case_y, y_pred)\n",
    "print(f\"mae is {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df = result_df[result_df.Location != 'DKI Jakarta'] # drop capital data\n",
    "mean_pop_density = result_df_new[\"Population Density\"].mean()\n",
    "mean_urban_rate = result_df_new[\"urban_ratio\"].mean()\n",
    "\n",
    "print(f\"median pop density: {median_pop_density} and median urban rate is : {median_urban_rate}\")\n",
    "\n",
    "# select 50% data from data that have pop density < median\n",
    "mask_urban = result_df_new['urban_ratio'] < mean_urban_rate\n",
    "left_percentile_urban =result_df_new[mask_urban]\n",
    "right_percentile_urban = result_df_new[~mask_urban]\n",
    "\n",
    "# further divide left data by median of pop density\n",
    "mask_pop_left = left_percentile_urban['Population Density'] < mean_pop_density\n",
    "mask_pop_right = right_percentile_urban['Population Density'] < mean_pop_density\n",
    "left_percentile_urban_pop_top = left_percentile_urban[mask_pop_left]\n",
    "left_percentile_urban_pop_down = left_percentile_urban[~mask_pop_left]\n",
    "\n",
    "# spilt the value into 2 groups\n",
    "left_case_down_train, left_case_down_test = np.array_split(left_percentile_urban_pop_down.sample(frac=1, random_state=42), 2)\n",
    "left_case_top_train, left_case_top_test = np.array_split(left_percentile_urban_pop_top.sample(frac=1, random_state=42), 2)\n",
    "\n",
    "# same with value on right hand side\n",
    "right_percentile_urban_pop_top = right_percentile_urban[mask_pop_right]\n",
    "right_percentile_urban_pop_down = right_percentile_urban[~mask_pop_right]\n",
    "right_case_down_train, right_case_down_test = np.array_split(right_percentile_urban_pop_down.sample(frac=1, random_state=42), 2)\n",
    "right_case_top_train, right_case_top_test = np.array_split(right_percentile_urban_pop_top.sample(frac=1, random_state=42), 2)\n",
    "\n",
    "\n",
    "# train data left side\n",
    "train_left = pd.concat([left_case_down_train,left_case_top_train])\n",
    "print(len(train_left))\n",
    "\n",
    "# train data right side\n",
    "train_right = pd.concat([right_case_down_train,right_case_top_train])\n",
    "print(len(train_right))\n",
    "\n",
    "# train data left side\n",
    "test_left = pd.concat([left_case_down_test,left_case_top_test])\n",
    "print(len(test_left))\n",
    "\n",
    "# train data right side\n",
    "test_right = pd.concat([right_case_down_test,right_case_top_test])\n",
    "print(len(test_right))\n",
    "\n",
    "# only select certain data\n",
    "test_case_x, test_case_y = test_left[[\"Population Density\", \"urban_ratio\"]], test_left[[\"New Deaths\"]]\n",
    "train_case_x, train_case_y = train_left[[\"Population Density\", \"urban_ratio\"]], train_left[[\"New Deaths\"]]\n",
    "\n",
    "# train a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(test_case_x, test_case_y)\n",
    "\n",
    "r_sq = model.score(test_case_x, test_case_y)\n",
    "print(f\"coefficient of determination: {r_sq}\")\n",
    "print(f\"intercept: {model.intercept_}\") # if we feed into the data of aceh this is the total infection 114734\n",
    "print(f\"slope: {model.coef_}\") # when population increase, result increase by 2.47e+02 for pop density\n",
    "\n",
    "y_pred = model.predict(train_case_x)\n",
    "print(f\"predicted response:\\n{y_pred}\")\n",
    "print(train_case_y)\n",
    "# accuracy of model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "r2_score = r2_score(train_case_y, y_pred)\n",
    "mse = mean_squared_error(train_case_y, y_pred, multioutput='uniform_average')\n",
    "\n",
    "print (f\"our accuracy score is {r2_score}\")\n",
    "print (f\"our MSE is {mse}\")\n",
    "print(f\"rmse is {np.sqrt(mse)}\")\n",
    "\n",
    "mae = mean_absolute_error(train_case_y, y_pred)\n",
    "print(f\"mae is {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "n_by_date = df.groupby('Date')[[\"New Cases\", \"New Deaths\"]].sum()\n",
    "\n",
    "# only select certain data\n",
    "test_case_x, train_case_x, test_case_y, train_case_y = train_test_split(n_by_date[[\"New Cases\"]], n_by_date[[\"New Deaths\"]], test_size=0.5, random_state=42)\n",
    "\n",
    "# train a linear regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(test_case_x, test_case_y)\n",
    "\n",
    "r_sq = model.score(test_case_x, test_case_y)\n",
    "print(\"result for new cases and death everyday\")\n",
    "print(f\"coefficient of determination: {r_sq}\")\n",
    "print(f\"intercept: {model.intercept_}\") # if we feed into the data of aceh this is the total infection 114734\n",
    "print(f\"slope: {model.coef_}\") # when population increase, result increase by 2.47e+02 for pop density\n",
    "\n",
    "y_pred = model.predict(train_case_x)\n",
    "print(train_case_y)\n",
    "# accuracy of model\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "r2_score = r2_score(train_case_y, y_pred)\n",
    "mse = mean_squared_error(train_case_y, y_pred, multioutput='uniform_average')\n",
    "\n",
    "print (f\"our accuracy score is {r2_score}\")\n",
    "print (f\"our MSE is {mse}\")\n",
    "print(f\"rmse is {np.sqrt(mse)}\")\n",
    "\n",
    "mae = mean_absolute_error(train_case_y, y_pred)\n",
    "print(f\"mae is {mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6e08394f27a7bfa2bb4e7efe66eae91ceaa77b3457ffe42cf775fad798ee67d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
