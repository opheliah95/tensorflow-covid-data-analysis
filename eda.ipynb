{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource('s3')\n",
    "\n",
    "for bucket in s3.buckets.all():\n",
    "    print(bucket.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # take environment variables from .env.\n",
    "\n",
    "import os # read dotenv values\n",
    "BUCKET_NAME = os.environ.get(\"BUCKET_NAME\")\n",
    "FILE_NAME = os.environ.get(\"CSV_NAME\")\n",
    "print(BUCKET_NAME)\n",
    "print(FILE_NAME)\n",
    "# read the content of data bucket\n",
    "bucket = s3.Bucket(BUCKET_NAME)\n",
    "\n",
    "\n",
    "# list all files in this bucket\n",
    "for obj in bucket.objects.all():\n",
    "    print(obj.key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv from s3\n",
    "import csv\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "import pandas as pd\n",
    "\n",
    "def from_s3(s3_uri:str) -> pd.DataFrame:\n",
    "    client = boto3.client(\"s3\")\n",
    "    parsed_s3 = urlparse(s3_uri)\n",
    "    path= parsed_s3.path[1:]\n",
    "    obj = client.get_object(Bucket=parsed_s3.netloc, Key=path)\n",
    "    csv_in_bytes = BytesIO(obj[\"Body\"].read())\n",
    "    print(obj[\"Body\"])\n",
    "    return pd.read_csv(csv_in_bytes)\n",
    "\n",
    "\n",
    "# read data from s3 bucket\n",
    "data_location = f\"s3://{BUCKET_NAME}/{FILE_NAME}\"\n",
    "df = from_s3 (data_location)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial data exploration to test if s3 is working\n",
    "df.head(100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = df.shape[1]\n",
    "print(df.shape)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop= [\"City or Regency\", \"Time Zone\", \"Country\", \"Continent\", \"Province\", \"Location ISO Code\", \"Total Regencies\", \"Island\", \"Special Status\", \"Longitude\", \"Latitude\", \"Location Level\", \"Area (km2)\"]\n",
    "df = df.drop(cols_to_drop, axis=1)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop indonisa columns, \n",
    "indo_rows_to_drop = df.loc[df[\"Location\"] == \"Indonesia\"]\n",
    "indo_rows_to_drop.head() \n",
    "index_to_delete = indo_rows_to_drop.index\n",
    "df.drop(index_to_delete, inplace=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean total rural village for jakarta\n",
    "# jakarta = df.loc[df[\"Location\"] == \"DKI Jakarta\"]\n",
    "# jakarta[\"Total Rural Villages\"] = 0\n",
    "# df.loc[\"Location\",\"DKI Jakarta\"] = jakarta\n",
    "\n",
    "df.loc[df[\"Location\"] == \"DKI Jakarta\", \"Total Rural Villages\"] = 0\n",
    "\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean percentage sign\n",
    "col_with_percent = [\"Case Fatality Rate\", \"Case Recovered Rate\"]\n",
    "print(df[col_with_percent].head())\n",
    "df[col_with_percent] = df[col_with_percent].apply( lambda s: s.str.rstrip('%').astype(float) / 100.0)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean na data\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill total city and total urban villages to 0 if there is nan\n",
    "df [\"Total Urban Villages\"] = df[\"Total Urban Villages\"].fillna(0)\n",
    "df [\"Total Cities\"] = df [\"Total Cities\"].fillna(0)\n",
    "\n",
    "# compare result\n",
    "df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interporate missing growth factor data\n",
    "df = df.interpolate(method ='linear', limit_direction ='forward')\n",
    "df.loc[0, \"Growth Factor of New Cases\"]= 0\n",
    "df.loc[0, \"Growth Factor of New Deaths\"]= 0\n",
    "# round off 2 decimals\n",
    "df[\"Growth Factor of New Cases\"] = df[\"Growth Factor of New Cases\"].apply(lambda x: round (x,3))\n",
    "df[\"Growth Factor of New Deaths\"] = df[\"Growth Factor of New Deaths\"].apply(lambda x: round (x,3))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# format the date\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload to bucket\n",
    "# save the cleaned csv locally\n",
    "result_file_name: str = os.environ.get(\"CSV_CLEANED_NAME\", \"result\")\n",
    "path=f\"{os.getcwd()}/{result_file_name}.csv\"\n",
    "print(path)\n",
    "df.to_csv(path)\n",
    "\n",
    "# upload csv to s3 bucket \n",
    "def to_s3(s3_uri:str, object_name:str = None) -> pd.DataFrame:\n",
    "    client = boto3.client(\"s3\")\n",
    "    parsed_s3 = urlparse(s3_uri)\n",
    "    file_name= parsed_s3.path[1:]\n",
    "    if object_name is None:\n",
    "        object_name = file_name\n",
    "    obj = client.upload_file(file_name, Bucket=parsed_s3.netloc,Key=object_name)\n",
    "    print(obj)\n",
    "\n",
    "\n",
    "# read data from s3 bucket\n",
    "upload_location = f\"s3://{BUCKET_NAME}/{result_file_name}.csv\"\n",
    "to_s3 (upload_location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial graphing of data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import numpy as np\n",
    "n_by_date = df.groupby('Date')[[\"Total Cases\", \"Total Deaths\"]].sum()\n",
    "n_by_date.head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = n_by_date[\"Total Cases\"]\n",
    "y = n_by_date[\"Total Deaths\"]\n",
    "\n",
    "x_scaler=10\n",
    "x_max_scaled = x.max() /x_scaler\n",
    "\n",
    "# Plot linear sequence, and set tick labels to the same color\n",
    "ax.set_ylim(0,x_max_scaled)\n",
    "ax.plot(y, color='red', label = \"Total Death\")\n",
    "ax.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Generate a new Axes instance, on the twin-X axes (same position)\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# Plot exponential sequence, set scale to logarithmic and change tick color\n",
    "ax2.plot(x, color='blue', label= \"Total Cases\")\n",
    "ax2.tick_params(axis='y', labelcolor='blue')\n",
    "ax2.ticklabel_format(useOffset=False, axis=\"y\", style=\"plain\")\n",
    "\n",
    "ax2.set_ylabel('Total Cases')\n",
    "ax2.set_xlabel(\"Total Death\")\n",
    "ax.set_xlabel('Date (by month)')\n",
    "\n",
    "fig.legend(loc = 'upper left')\n",
    "plt.title(\"Total Death and Total Cases by month\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new death and cases\n",
    "n_by_date = df.groupby('Date')[[\"New Cases\", \"New Deaths\"]].sum()\n",
    "n_by_date.head(50)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x_label, y_label = [\"New Cases\", \"New Deaths\"]\n",
    "\n",
    "x = n_by_date[x_label]\n",
    "y = n_by_date[y_label]\n",
    "\n",
    "x_scaler=10\n",
    "x_max_scaled = x.max() /x_scaler\n",
    "\n",
    "# Plot linear sequence, and set tick labels to the same color\n",
    "ax.set_ylim(0,x_max_scaled)\n",
    "ax.plot(y, color='red', label = y_label)\n",
    "ax.tick_params(axis='y', labelcolor='red')\n",
    "\n",
    "# Generate a new Axes instance, on the twin-X axes (same position)\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "# Plot exponential sequence, set scale to logarithmic and change tick color\n",
    "ax2.plot(x, color='blue', label= x_label)\n",
    "ax2.tick_params(axis='y', labelcolor='blue')\n",
    "ax2.ticklabel_format(useOffset=False, axis=\"y\", style=\"plain\")\n",
    "\n",
    "ax2.set_ylabel(x_label)\n",
    "ax.set_ylabel(y_label)\n",
    "ax.set_xlabel('Date (by month)')\n",
    "\n",
    "fig.legend(loc = 'upper left')\n",
    "plt.title(f\"{x_label} and {y_label} by month\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by region \n",
    "\n",
    "n_by_date = df.groupby(['Date', 'Location'])[[\"New Cases\", \"New Deaths\"]].sum()\n",
    "print(type(n_by_date))\n",
    "print(n_by_date.columns)\n",
    "\n",
    "# all unique locations\n",
    "# all_locations = df[\"Location\"].unique()\n",
    "# print(all_locations)\n",
    "print(n_by_date.loc[n_by_date['New Cases']==n_by_date['New Cases'].max()])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "n_by_date[\"New Cases\"].unstack().plot(ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new death by locations\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,15))\n",
    "n_by_date[\"New Deaths\"].unstack().plot(ax=ax)\n",
    "print(n_by_date.loc[n_by_date['New Deaths']==n_by_date['New Deaths'].max()])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by region \n",
    "\n",
    "n_by_loc = df.groupby(['Location'])[[\"New Cases\", \"New Deaths\"]].sum()\n",
    "\n",
    "# print(n_by_loc.loc[n_by_date['New Deaths']==n_by_date['New Deaths'].max()])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(25, 20))\n",
    "\n",
    "x_label, y_label = [\"New Cases\", \"New Deaths\"]\n",
    "\n",
    "x = n_by_date[x_label]\n",
    "y = n_by_date[y_label]\n",
    "\n",
    "x_scaler=10\n",
    "x_max_scaled = x.max() / x_scaler\n",
    "\n",
    "\n",
    "# plot second bar chart on same graph\n",
    "ind = np.arange(len(n_by_loc))\n",
    "width = 0.4\n",
    "\n",
    "# Plot linear sequence, and set tick labels to the same color\n",
    "# ax.set_ylim(0,x_max_scaled)\n",
    "ax.barh(ind, y*x_scaler, width, color='red', label = y_label)\n",
    "ax.barh(ind+width, x, width, color='blue', label = x_label)\n",
    "ax.tick_params(axis='x', labelcolor='blue')\n",
    "ax.set(yticks=ind + width, yticklabels=n_by_loc.index, ylim=[2*width - 1, len(n_by_loc)])\n",
    "ax.legend()\n",
    "\n",
    "\n",
    "ax.set_xlabel(f\"{x_label} by Location\")\n",
    "# secax = ax.secondary_xaxis('top')\n",
    "\n",
    "ax2 = ax.twiny()\n",
    "ax2.set_xlim(0,y.max() * 1.2)\n",
    "x_death_range = np.arange(0, x_max_scaled, 10000)\n",
    "ax2.set_xticks(x_death_range)\n",
    "ax2.tick_params(axis='x', labelcolor='red')\n",
    "ax2.set_xlabel(f\"{y_label} by Location\")\n",
    "              \n",
    "# # Add annotation to bars\n",
    "# for i in ax.patches:\n",
    "#     plt.text(i.get_width()+0.2, i.get_y()+0.2,\n",
    "#              str(round((i.get_width() / x_scaler), 5)),\n",
    "#              fontsize = 5, fontweight ='bold',\n",
    "#              color ='grey')\n",
    "\n",
    "for p in ax.patches:\n",
    "    width, height = p.get_width(), p.get_height()\n",
    "    x, y = p.get_xy() \n",
    "    ax.text(x+width, \n",
    "            y+height/2, \n",
    "            str(round(width/x_scaler)), \n",
    "            fontsize=8,\n",
    "           color='grey')\n",
    "\n",
    "plt.title(f\"{x_label} and {y_label} by Location\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_by_loc = df.groupby(['Location'])[[\"New Cases\", \"New Deaths\"]].sum()\n",
    "location_pop = df[['Location', 'Population Density']]\n",
    "# get unique location's population density\n",
    "location_pop=location_pop.drop_duplicates(subset=['Location'])\n",
    "\n",
    "# combine dataframes\n",
    "result_df = n_by_loc.merge(location_pop, how = 'inner', on = ['Location'])\n",
    "result_df.head(40)\n",
    "\n",
    "# bco efficients between data\n",
    "import numpy as np\n",
    "death = result_df['New Deaths']\n",
    "case = result_df['New Cases']\n",
    "density = result_df['Population Density']\n",
    "r_death_loc = np.corrcoef(density, death)\n",
    "print(f'the coefficient between density and death is {r_death_loc}')\n",
    "r_death_case = np.corrcoef(case, death)\n",
    "print(f'the coefficient between case and death is {r_death_case}')\n",
    "r_case_loc = np.corrcoef(density, case)\n",
    "print(f'the coefficient between density and case is {r_case_loc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_by_loc = df.groupby(['Location'])[[\"New Cases\", \"New Deaths\"]].sum()\n",
    "urban_df = df[['Location', 'Total Cities', 'Total Districts', 'Total Urban Villages', 'Total Rural Villages']]\n",
    "# get unique location's population density\n",
    "urban_df = urban_df.drop_duplicates(subset=['Location'])\n",
    "\n",
    "urban_df['rural_ratio'] = urban_df['Total Rural Villages'] / (urban_df['Total Rural Villages'] + urban_df['Total Districts'] + urban_df['Total Urban Villages'] + urban_df['Total Cities'])\n",
    "\n",
    "\n",
    "urban_df['urban_ratio'] = 1- urban_df['rural_ratio']\n",
    "\n",
    "urban_df.head()\n",
    "\n",
    "# combine dataframes\n",
    "result_df = n_by_loc.merge(urban_df, how = 'inner', on = ['Location'])\n",
    "result_df.head(40)\n",
    "\n",
    "# bco efficients between data\n",
    "import numpy as np\n",
    "death = result_df['New Deaths']\n",
    "case = result_df['New Cases']\n",
    "urban_rate = result_df['urban_ratio']\n",
    "rural_rate = result_df['rural_ratio'] \n",
    "\n",
    "r_death_urban = np.corrcoef(urban_rate, death)\n",
    "print(f'the coefficient between urban_rate and death is {r_death_urban}')\n",
    "\n",
    "r_death_rural = np.corrcoef(rural_rate, death)\n",
    "print(f'the coefficient between rural_rate and death is {r_death_rural}')\n",
    "\n",
    "r_death_case = np.corrcoef(urban_rate, case)\n",
    "print(f'the coefficient between urban_rate and case is {r_death_case}')\n",
    "r_case_loc = np.corrcoef(rural_rate, case)\n",
    "print(f'the coefficient between rural and case is {r_case_loc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_by_loc = df.groupby(['Location'])[[\"New Cases\", \"New Deaths\"]].sum()\n",
    "location_pop = df[['Location', 'Population Density']]\n",
    "# get unique location's population density\n",
    "location_pop=location_pop.drop_duplicates(subset=['Location'])\n",
    "result_df = result_df.merge(location_pop, how = 'inner', on = ['Location'])\n",
    "result_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 20))\n",
    "\n",
    "x_label, y_label = [\"rural_ratio\", \"New Deaths\"]\n",
    "\n",
    "x = result_df[x_label]\n",
    "y = result_df[y_label]\n",
    "\n",
    "for i, txt in enumerate(result_df['Location']):\n",
    "    ax.annotate(txt, (x[i], y[i]))\n",
    "\n",
    "plt.scatter (x, y, s=80)\n",
    "plt.title(\"rural area and total death\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(25, 20))\n",
    "\n",
    "x_label, y_label = [\"urban_ratio\", \"New Deaths\"]\n",
    "\n",
    "x = result_df[x_label]\n",
    "y = result_df[y_label]\n",
    "\n",
    "plt.scatter (x, y)\n",
    "plt.title (\"urban area and total covid death\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rural_percentage = result_df.loc[result_df[\"rural_ratio\"] > 0.7]\n",
    "total_rural_locations = len(rural_percentage)\n",
    "\n",
    "print(f\"in indonisa {total_rural_locations / len(result_df) :.2%} percent are in rural area, as the city to village ratio is > 0.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e6e08394f27a7bfa2bb4e7efe66eae91ceaa77b3457ffe42cf775fad798ee67d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
